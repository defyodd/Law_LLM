import os
import re
import datetime
from typing import List, Dict, Any

from openai import OpenAI

from .search_faiss_index import LawFAISSSearcher
from .build_index import LawFAISSIndexBuilder
from langchain.memory import ConversationBufferMemory
import logging
import sys, io

logger = logging.getLogger(__name__)

# ç”¨ UTF-8 åŒ…è£…æ ‡å‡†è¾“å…¥è¾“å‡º
sys.stdin  = io.TextIOWrapper(sys.stdin.buffer,  encoding='utf-8')
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

class LawAgent:
    """æ™ºèƒ½æ³•å¾‹åŠ©æ‰‹Agent"""
    def __init__(self, index_dir: str = "../FAISS/indexes"):
        """
        åˆå§‹åŒ–æ³•å¾‹Agent
        """
        self.index_dir = index_dir
        self.searcher = None
        self.conversation_history = []
        self.memory = ConversationBufferMemory(return_messages=True)
        self._initialize_index()
        self.llm = self._initialize_llm()

    def _initialize_index(self):
        """åˆå§‹åŒ–æˆ–æ„å»ºFAISSç´¢å¼•"""
        try:
            if self._check_index():
                print("ğŸ¤– æ³•å¾‹åŠ©æ‰‹æ­£åœ¨å¯åŠ¨ï¼ŒåŠ è½½çŸ¥è¯†åº“...", flush=True)
                self.searcher = LawFAISSSearcher(self.index_dir)
                print("âœ… çŸ¥è¯†åº“åŠ è½½å®Œæ¯•", flush=True)
            else:
                self._build_index()
        except Exception as e:
            logger.error(f"âŒ ç´¢å¼•åˆå§‹åŒ–å¤±è´¥: {e}")
            raise

    def _check_index(self) -> bool:
        """æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨"""
        return os.path.exists(os.path.join(self.index_dir, 'law_faiss_index.bin'))

    def _build_index(self):
        """ä»JSONæ–‡ä»¶æ„å»ºFAISSç´¢å¼•"""
        print("ğŸ”¨ æ­£åœ¨æ„å»ºæ³•å¾‹çŸ¥è¯†åº“...", flush=True)
        json_dir = "../../../crawled data/cleaned_data"
        builder = LawFAISSIndexBuilder()
        builder.build_index_from_json_dir(json_dir, self.index_dir)
        self.searcher = LawFAISSSearcher(self.index_dir)
        print("âœ… çŸ¥è¯†åº“æ„å»ºå®Œæˆ", flush=True)

    def _initialize_llm(self):
        api_key = 'sk-de88dee6506d49c59ccaecb8abd91045'
        if not api_key:
            raise ValueError("1")
        llm = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com"
        )
        print("ğŸ¤– DeepSeek æ¨¡å‹å·²é…ç½®", flush=True)
        return llm

    def _extract_keywords(self, query: str) -> List[str]:
        """ä»æŸ¥è¯¢ä¸­æå–å¸¸è§æ³•å¾‹å…³é”®è¯"""
        legal_keywords = [
            'åˆåŒ', 'è¿çº¦', 'èµ”å¿', 'è´£ä»»', 'æƒåˆ©', 'ä¹‰åŠ¡', 'å©šå§»', 'ç¦»å©š',
            'ç»§æ‰¿', 'è´¢äº§', 'ä¾µæƒ', 'æŸå®³', 'ç‰©æƒ', 'å€ºæƒ', 'æ‹…ä¿', 'æŠµæŠ¼',
            'ç§Ÿèµ', 'ä¹°å–', 'å€Ÿè´·', 'åŠ³åŠ¨', 'å·¥ä¼¤', 'ä¿é™©', 'è¯‰è®¼', 'ä»²è£'
        ]
        return [kw for kw in legal_keywords if kw in query]

    def _analyze_query_type(self, query: str) -> str:
        """åˆ†ææŸ¥è¯¢ç±»å‹"""
        if any(w in query for w in ['ä»€ä¹ˆ', 'å¦‚ä½•', 'æ€ä¹ˆ', 'æ€æ ·']):
            return "å®šä¹‰å’¨è¯¢"
        if any(w in query for w in ['èƒ½å¦', 'å¯ä»¥', 'æ˜¯å¦', 'èƒ½ä¸èƒ½']):
            return "å¯è¡Œæ€§å’¨è¯¢"
        if any(w in query for w in ['è´£ä»»', 'èµ”å¿', 'å¤„ç½š', 'åæœ']):
            return "è´£ä»»å’¨è¯¢"
        if any(w in query for w in ['æµç¨‹', 'ç¨‹åº', 'æ­¥éª¤', 'æ‰‹ç»­']):
            return "ç¨‹åºå’¨è¯¢"
        return "ä¸€èˆ¬å’¨è¯¢"
    
    def _self_evaluate(self, answer, question):
        try:
            eval_prompt = f"é—®é¢˜ï¼š{question}\nç­”æ¡ˆï¼š{answer}\nå›ç­”æ˜¯å¦å……åˆ†æ˜ç¡®ï¼Ÿä¸å……åˆ†åˆ™è¿”å›'é‡è¯•'ï¼Œå¦åˆ™'é€šè¿‡'ã€‚"
            resp = self.llm.chat.completions.create(
                model="deepseek-chat", 
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯è¯„ä¼°å‘˜ã€‚"}, 
                    {"role": "user", "content": eval_prompt}
                ],
                temperature=0.1,
                max_tokens=50
            )
            
            if not resp.choices or not hasattr(resp.choices[0].message, 'content'):
                return 'é€šè¿‡'  # å¦‚æœè¯„ä¼°å¤±è´¥ï¼Œé»˜è®¤é€šè¿‡
            
            return resp.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"è‡ªè¯„ä¼°å¤±è´¥: {str(e)}")
            return 'é€šè¿‡'  # å¦‚æœè¯„ä¼°å¤±è´¥ï¼Œé»˜è®¤é€šè¿‡

    def _check_clarity(self, question):
        try:
            prompt = f"é—®é¢˜ï¼š'{question}' æ˜¯å¦è¶³å¤Ÿæ¸…æ™°å›ç­”ï¼Ÿè‹¥æ¨¡ç³Šè¯·æŒ‡å‡ºéœ€è¡¥å……çš„ä¿¡æ¯ï¼Œå¦åˆ™è¿”å›'æ¸…æ™°'ã€‚"
            resp = self.llm.chat.completions.create(
                model="deepseek-chat", 
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=100
            )
            
            if not resp.choices or not hasattr(resp.choices[0].message, 'content'):
                return 'æ¸…æ™°'  # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œé»˜è®¤æ¸…æ™°
            
            return resp.choices[0].message.content.strip()
        except Exception as e:
            logger.error(f"æ¸…æ™°åº¦æ£€æŸ¥å¤±è´¥: {str(e)}")
            return 'æ¸…æ™°'  # å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œé»˜è®¤æ¸…æ™°

    # def answer(self, question: str, max_results: int = 5, model: str = "deepseek-chat") -> Dict[str, Any]:
    #     try:
    #         query_type = self._analyze_query_type(question)
    #         keywords = self._extract_keywords(question)
    #         results = self.searcher.search(question, top_k=max_results)
    #         answer_text = self._generate_answer(question, results, query_type, model)
    #         eval_result = self._self_evaluate(answer_text, question)
    #         if eval_result == 'é‡è¯•':
    #             answer_text += "\n\nï¼ˆæ³¨æ„ï¼šç­”æ¡ˆå¯èƒ½ä¸å®Œå…¨æ˜ç¡®ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆã€‚ï¼‰"
    #
    #         response = {
    #             'question': question,
    #             'query_type': query_type,
    #             'keywords': keywords,
    #             'answer': answer_text,
    #             'relevant_articles': results,
    #             'confidence': self._calculate_confidence(results),
    #             'suggestions': self._generate_suggestions(results, query_type),
    #             'agent': 'LawAgent',
    #             'type': 'chat'  # æ·»åŠ ç±»å‹æ ‡è¯†
    #         }
    #
    #         self.memory.save_context({"input": question}, {"output": answer_text})
    #         self.conversation_history.append({
    #             'question': question,
    #             'response': response,
    #             'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    #         })
    #
    #         return response
    #
    #     except Exception as e:
    #         logger.error(f"LawAgent.answer å‡ºç°å¼‚å¸¸: {str(e)}", exc_info=True)
    #         # è¿”å›é”™è¯¯å¤„ç†å“åº”
    #         return {
    #             'question': question,
    #             'query_type': 'é”™è¯¯å¤„ç†',
    #             'keywords': [],
    #             'answer': f'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}ã€‚è¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚',
    #             'relevant_articles': [],
    #             'confidence': 0.0,
    #             'suggestions': ['è¯·é‡æ–°æé—®æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ'],
    #             'agent': 'LawAgent',
    #             'type': 'chat'
    #         }
    def _is_legal_question_by_llm(self, question: str) -> bool:
        prompt = f"""è¯·åˆ¤æ–­ä¸‹é¢ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦å±äºæ³•å¾‹ç›¸å…³é—®é¢˜ï¼Œä»…å›ç­”â€œæ˜¯â€æˆ–â€œå¦â€ï¼Œä¸è¦è¾“å‡ºå¤šä½™å†…å®¹ï¼š

    ç”¨æˆ·é—®é¢˜ï¼š{question}
    """
        try:
            resp = self.llm.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "user", "content": prompt}
                ],
                temperature=0.0,
                max_tokens=2
            )
            content = resp.choices[0].message.content.strip()
            return content.startswith('æ˜¯')
        except Exception as e:
            logger.error(f"æ³•å¾‹é¢†åŸŸåˆ¤å®šLLMè°ƒç”¨å¤±è´¥: {e}")
            # å¦‚æœå‡ºé”™ï¼Œé»˜è®¤èµ°RAGæµç¨‹
            return True
    def answer(self, question: str, max_results: int = 5, model: str = "deepseek-chat", context_chats: list = None) -> Dict[str, Any]:
        try:

            if not self._is_legal_question_by_llm(question):
                # éæ³•å¾‹é—®é¢˜ï¼Œç›´æ¥ç”¨LLMå¯¹è¯ç”Ÿæˆç­”æ¡ˆ
                system_msg = "ä½ æ˜¯ä¸€ä½æ™ºèƒ½åŠ©æ‰‹ï¼Œè¯·ç®€æ´å‡†ç¡®åœ°å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœä½ æ— æ³•å›ç­”ï¼Œè¯·ç›´æ¥è¯´æ˜ã€‚"
                
                # æ„å»ºå¯¹è¯å†å²
                messages = [{"role": "system", "content": system_msg}]
                
                # æ·»åŠ ä¸Šä¸‹æ–‡å¯¹è¯è®°å½•
                if context_chats:
                    for chat in context_chats:
                        if chat.prompt and chat.answer:
                            messages.append({"role": "user", "content": chat.prompt})
                            messages.append({"role": "assistant", "content": chat.answer})
                
                # æ·»åŠ å½“å‰é—®é¢˜
                messages.append({"role": "user", "content": question})
                
                try:
                    resp = self.llm.chat.completions.create(
                        model=model,
                        messages=messages,
                        stream=False,
                        temperature=0.7,
                        max_tokens=2000
                    )
                    answer_text = resp.choices[0].message.content.strip() if resp.choices else "æŠ±æ­‰ï¼ŒAIæœªèƒ½å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
                except Exception as e:
                    answer_text = f"æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}"

                response = {
                    'question': question,
                    'query_type': 'ä¸€èˆ¬å’¨è¯¢',
                    'keywords': [],
                    'answer': answer_text,
                    'relevant_articles': [],
                    'confidence': 0.9,
                    'suggestions': [],
                    'agent': 'LawAgent',
                    'type': 'chat'
                }
                self.memory.save_context({"input": question}, {"output": answer_text})
                self.conversation_history.append({
                    'question': question,
                    'response': response,
                    'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
                return response

            # ====== ä¸‹é¢æ˜¯ä½ åŸæœ‰çš„â€œæ³•å¾‹é—®é¢˜â€RAGæµç¨‹ ======
            query_type = self._analyze_query_type(question)
            keywords = self._extract_keywords(question)
            results = self.searcher.search(question, top_k=max_results)
            answer_text = self._generate_answer(question, results, query_type, model, context_chats)
            eval_result = self._self_evaluate(answer_text, question)
            if eval_result == 'é‡è¯•':
                answer_text += "\n\nï¼ˆæ³¨æ„ï¼šç­”æ¡ˆå¯èƒ½ä¸å®Œå…¨æ˜ç¡®ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆã€‚ï¼‰"

            response = {
                'question': question,
                'query_type': query_type,
                'keywords': keywords,
                'answer': answer_text,
                'relevant_articles': results,
                'confidence': self._calculate_confidence(results),
                'suggestions': self._generate_suggestions(results, query_type),
                'agent': 'LawAgent',
                'type': 'chat'
            }

            self.memory.save_context({"input": question}, {"output": answer_text})
            self.conversation_history.append({
                'question': question,
                'response': response,
                'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })

            return response

        except Exception as e:
            logger.error(f"LawAgent.answer å‡ºç°å¼‚å¸¸: {str(e)}", exc_info=True)
            # è¿”å›é”™è¯¯å¤„ç†å“åº”
            return {
                'question': question,
                'query_type': 'é”™è¯¯å¤„ç†',
                'keywords': [],
                'answer': f'æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {str(e)}ã€‚è¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚',
                'relevant_articles': [],
                'confidence': 0.0,
                'suggestions': ['è¯·é‡æ–°æé—®æˆ–è”ç³»æŠ€æœ¯æ”¯æŒ'],
                'agent': 'LawAgent',
                'type': 'chat'
            }



    def _generate_answer(self, question: str, results: List[Dict], query_type: str,
                         model: str = "deepseek-chat", context_chats: list = None) -> str:
        # æ„å»ºæ£€ç´¢åˆ°çš„æ³•æ¡å†…å®¹
        context = ""
        if results:
            try:
                context = "\n".join([
                    f"ã€{art.get('article_no', 'æœªçŸ¥æ¡æ–‡')}ã€‘{art.get('article_content', art.get('content', 'å†…å®¹ç¼ºå¤±'))}"
                    for art in results[:3]
                ])
            except Exception as e:
                logger.error(f"æ„å»ºæ³•æ¡å†…å®¹æ—¶å‡ºé”™: {str(e)}")
                context = "æ³•æ¡å†…å®¹å¤„ç†å¤±è´¥"

        # ç³»ç»Ÿæç¤ºè¯
        system_msg = """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ³•å¾‹åŠ©æ‰‹ï¼Œå…·å¤‡æ·±åšçš„æ³•å¾‹çŸ¥è¯†ã€‚è¯·åŸºäºæä¾›çš„æ³•æ¡å†…å®¹å›ç­”ç”¨æˆ·çš„æ³•å¾‹é—®é¢˜ã€‚

    å›ç­”è¦æ±‚ï¼š
    1. å‡†ç¡®å¼•ç”¨ç›¸å…³æ³•æ¡
    2. è¯­è¨€é€šä¿—æ˜“æ‡‚ï¼Œé¿å…è¿‡äºä¸“ä¸šçš„æœ¯è¯­
    3. ç»“åˆå…·ä½“æƒ…å†µç»™å‡ºå®ç”¨å»ºè®®
    4. å¦‚æœæ³•æ¡ä¸è¶³ä»¥å®Œå…¨å›ç­”é—®é¢˜ï¼Œè¯·è¯šå®è¯´æ˜
    5. æé†’ç”¨æˆ·åœ¨å…·ä½“æ¡ˆä»¶ä¸­å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ"""

        # ç”¨æˆ·æ¶ˆæ¯
        user_msg = f"""ç”¨æˆ·é—®é¢˜ï¼š{question}

    æŸ¥è¯¢ç±»å‹ï¼š{query_type}

    ç›¸å…³æ³•æ¡ï¼š
    {context if context else "æœªæ‰¾åˆ°ç›´æ¥ç›¸å…³çš„æ³•æ¡"}

    è¯·åŸºäºä¸Šè¿°æ³•æ¡å†…å®¹ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å®ç”¨çš„æ³•å¾‹è§£ç­”ã€‚"""

        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œä¼˜å…ˆä½¿ç”¨æ•°æ®åº“ä¸­çš„ä¸Šä¸‹æ–‡è®°å½•
        messages = [{"role": "system", "content": system_msg}]
        
        # æ·»åŠ æ•°æ®åº“ä¸­çš„ä¸Šä¸‹æ–‡å¯¹è¯è®°å½•
        if context_chats:
            for chat in context_chats:
                if chat.prompt and chat.answer:
                    messages.append({"role": "user", "content": chat.prompt})
                    messages.append({"role": "assistant", "content": chat.answer})
        
        # å¦‚æœæ²¡æœ‰æ•°æ®åº“ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨å†…å­˜ä¸­çš„å†å²è®°å½•ä½œä¸ºåå¤‡
        elif hasattr(self, 'memory'):
            history = self.memory.load_memory_variables({}).get("history", [])
            for h in history[-3:]:  # åªå–æœ€è¿‘3è½®
                if hasattr(h, 'input') and hasattr(h, 'output'):
                    messages.append({"role": "user", "content": h.input})
                    messages.append({"role": "assistant", "content": h.output})
        
        # æ·»åŠ å½“å‰é—®é¢˜
        messages.append({"role": "user", "content": user_msg})

        # è°ƒç”¨LLMç”Ÿæˆå›ç­”
        try:
            resp = self.llm.chat.completions.create(
                model=model,
                messages=messages,
                stream=False,
                temperature=0.7,
                max_tokens=2000
            )
            
            # æ£€æŸ¥å“åº”æ ¼å¼
            if not resp.choices:
                return "æŠ±æ­‰ï¼ŒAIæ¨¡å‹æœªè¿”å›æœ‰æ•ˆå›ç­”ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            
            if not hasattr(resp.choices[0].message, 'content') or resp.choices[0].message.content is None:
                return "æŠ±æ­‰ï¼ŒAIæ¨¡å‹å“åº”æ ¼å¼å¼‚å¸¸ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            
            return resp.choices[0].message.content
            
        except Exception as e:
            logger.error(f"LLMè°ƒç”¨å¤±è´¥: {str(e)}")
            return f"æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨: {str(e)}"

    def _calculate_confidence(self, results: List[Dict]) -> float:
        """åŸºäºæœ€é«˜ç›¸ä¼¼åº¦è¯„åˆ†ä¼°ç®—ç½®ä¿¡åº¦"""
        if not results:
            return 0.0
        score = results[0]['score']
        if score > 0.8: return 0.9
        if score > 0.6: return 0.7
        if score > 0.4: return 0.5
        return 0.3

    def _generate_suggestions(self, results: List[Dict], query_type: str) -> List[str]:
        """æ ¹æ®ç½®ä¿¡åº¦å’Œç±»å‹ç”Ÿæˆå»ºè®®"""
        if not results:
            return ["å»ºè®®é‡æ–°æè¿°é—®é¢˜æˆ–ä½¿ç”¨æ›´å…·ä½“çš„æ³•å¾‹æœ¯è¯­"]
        conf = self._calculate_confidence(results)
        sugg = []
        if conf >= 0.8:
            sugg.append("æ‰¾åˆ°äº†é«˜åº¦ç›¸å…³çš„æ³•æ¡ï¼Œå»ºè®®ä»”ç»†é˜…è¯»")
        elif conf >= 0.6:
            sugg.append("æ‰¾åˆ°äº†ç›¸å…³çš„æ³•æ¡ï¼Œå»ºè®®ç»“åˆå…·ä½“æƒ…å†µåˆ†æ")
        else:
            sugg.append("ç›¸å…³åº¦ä¸€èˆ¬ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ")
        if query_type == "ç¨‹åºå’¨è¯¢":
            sugg.append("å¯¹äºå…·ä½“ç¨‹åºé—®é¢˜ï¼Œå»ºè®®å’¨è¯¢å½“åœ°ç›¸å…³éƒ¨é—¨")
        if query_type == "è´£ä»»å’¨è¯¢":
            sugg.append("å…·ä½“è´£ä»»è®¤å®šéœ€è¦ç»“åˆå®é™…æ¡ˆä»¶æƒ…å†µ")
        return sugg

    def print_answer(self, rsp: Dict[str, Any]):
        """æ ¼å¼åŒ–æ‰“å°å›ç­”"""
        print("\n" + "="*60, flush=True)
        print("ğŸ¤– æ³•å¾‹åŠ©æ‰‹å›ç­”", flush=True)
        print("="*60, flush=True)
        print(f"â“ é—®é¢˜ç±»å‹ï¼š{rsp['query_type']}", flush=True)
        if rsp['keywords']:
            print(f"ğŸ”‘ å…³é”®è¯ï¼š{', '.join(rsp['keywords'])}", flush=True)
        print("ğŸ“ å›ç­”ï¼š", flush=True)
        print(rsp['answer'], flush=True)
        print(f"\nğŸ“Š ç½®ä¿¡åº¦ï¼š{rsp['confidence']:.1%}", flush=True)
        if rsp['suggestions']:
            print("\nğŸ’¡ å»ºè®®ï¼š", flush=True)
            for i, s in enumerate(rsp['suggestions'], 1):
                print(f"   {i}. {s}", flush=True)
        print("\nğŸ“š å‚è€ƒæ³•æ¡ï¼š", flush=True)
        for i, art in enumerate(rsp['relevant_articles'][:3], 1):
            print(f"   {i}. {art['article_no']} (ç›¸å…³åº¦: {art['score']:.3f})", flush=True)


def interactive_agent():
    """äº¤äº’å¼Agentæµ‹è¯•"""
    print("ğŸ¤– æ™ºèƒ½æ³•å¾‹åŠ©æ‰‹ Agent å¯åŠ¨", flush=True)
    print("="*50, flush=True)
    print("ğŸ’¡ æˆ‘å¯ä»¥å¸®æ‚¨ï¼š", flush=True)
    print("   â€¢ æŸ¥æ‰¾ç›¸å…³æ³•å¾‹æ¡æ–‡", flush=True)
    print("   â€¢ è§£ç­”æ³•å¾‹é—®é¢˜", flush=True)
    print("   â€¢ æä¾›æ³•å¾‹å»ºè®®", flush=True)
    print("\nè¾“å…¥ 'quit' é€€å‡ºï¼Œ'help' æŸ¥çœ‹ç¤ºä¾‹", flush=True)

    agent = LawAgent()
    while True:
        try:
            print("\n" + "-"*50, flush=True)
            question = input("ğŸ—£ï¸  è¯·æè¿°æ‚¨çš„æ³•å¾‹é—®é¢˜ï¼š").strip()
            if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                print("ğŸ‘‹ æ„Ÿè°¢å’¨è¯¢ï¼Œå†è§ï¼", flush=True)
                break
            if question.lower() == 'help':
                examples = [
                    "åˆåŒè¿çº¦æ€ä¹ˆåŠï¼Ÿ",
                    "ç¦»å©šè´¢äº§å¦‚ä½•åˆ†å‰²ï¼Ÿ",
                    "æˆ¿å±‹ä¹°å–åˆåŒæœ‰ä»€ä¹ˆè¦æ±‚ï¼Ÿ",
                    "äº¤é€šäº‹æ•…è´£ä»»å¦‚ä½•è®¤å®šï¼Ÿ",
                    "åŠ³åŠ¨åˆåŒå¯ä»¥éšæ—¶è§£é™¤å—ï¼Ÿ"
                ]
                print("\nğŸ“ ç¤ºä¾‹é—®é¢˜ï¼š", flush=True)
                for ex in examples:
                    print(f"   â€¢ {ex}", flush=True)
                continue
            if not question:
                print("è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜", flush=True)
                continue
            rsp = agent.answer(question)
            if rsp.get('status') == 'clarify':
                print(f"â— è¯·è¡¥å……ä¿¡æ¯ï¼š{rsp['message']}", flush=True)
            else:
                agent.print_answer(rsp)
            agent.print_answer(rsp)
        except KeyboardInterrupt:
            print("\nğŸ‘‹ åŠ©æ‰‹å·²å…³é—­", flush=True)
            break
        except Exception as e:
            print(f"âŒ ç³»ç»Ÿé”™è¯¯ï¼š{e}", flush=True)

# if __name__ == "__main__":
#     interactive_agent()